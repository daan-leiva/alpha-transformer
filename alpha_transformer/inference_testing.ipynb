{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d89aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# test model loading and vocab loading\n",
    "import torch\n",
    "from transformer.transformer import Transformer\n",
    "import torch.nn as nn\n",
    "from trainer import Trainer\n",
    "from data.translation_data import TranslationData\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29fcae7",
   "metadata": {},
   "source": [
    "# Test Loading a model, vocabulary and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c78dc211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SP piece size ('vocab size'): 16000\n",
      "Loading dataset...\n",
      "Data num_workers: 4\n",
      "Data Loaders ready\n",
      "Cuda available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 4.1187 | BLEU Score: 4.80\n"
     ]
    }
   ],
   "source": [
    "# create device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# load best model\n",
    "model_path = './checkpoints/en_fr_large_512_long/best_model.pt'\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "\n",
    "# load hypter parameters\n",
    "args = checkpoint['args']\n",
    "\n",
    "# get tokenizers form sentence piece\n",
    "sp_tokenizer = spm.SentencePieceProcessor()\n",
    "sp_tokenizer.load(args['sp_model_path'])\n",
    "\n",
    "print(f\"SP piece size ('vocab size'): {sp_tokenizer.get_piece_size()}\")\n",
    "model = Transformer(vocab_size=sp_tokenizer.get_piece_size(), d_model=args['d_model'], n_heads=args['n_heads'],\n",
    "                       max_len=args['max_len'], dropout_rate = args['dropout_rate'],\n",
    "                       hidden_ff_d=args['d_model']*4,\n",
    "                       num_encoder_layers=args['num_layers'],\n",
    "                       num_decoder_layers=args['num_layers'], encoding_type=args['encoding_type']).to(device=device)\n",
    "\n",
    "# load dataset\n",
    "data_module = TranslationData(src_lang='en', tgt_lang='fr', batch_size=args['batch_size'],\n",
    "                              max_len=args['max_len'], tokenizer=sp_tokenizer)\n",
    "data_module.prepare_data()\n",
    "# get validation loader\n",
    "_, valid_loader, _ = data_module.get_dataloaders()\n",
    "\n",
    "# create a trainer object for inference\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=data_module.special_tokens['<pad>'])\n",
    "trainer = Trainer(model=model, val_loader=valid_loader, loss_fn=loss_fn, tokenizer=sp_tokenizer)\n",
    "trainer.load_checkpoint(path=model_path)\n",
    "# run validation only\n",
    "val_loss, bleu_score = trainer.validate()\n",
    "print(f\"Val Loss: {val_loss:.04f} | BLEU Score: {bleu_score:.02f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382d9b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_740067/1275440744.py:33: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
      "  torch.onnx.export(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `Transformer([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `Transformer([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 18 of general pattern rewrite rules.\n",
      "✅ ONNX export completed: transformer.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "import os\n",
    "\n",
    "# --- Preparation ---\n",
    "model.eval()\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Create dummy input tensors (match your real shape and vocab size)\n",
    "batch_size = args['batch_size']\n",
    "max_len = args['max_len']\n",
    "vocab_size = 16000\n",
    "pad_token_id = data_module.special_tokens['<pad>']\n",
    "\n",
    "src = torch.randint(0, vocab_size, (batch_size, max_len), dtype=torch.long).to(device)\n",
    "tgt = torch.randint(0, vocab_size, (batch_size, max_len), dtype=torch.long).to(device)\n",
    "\n",
    "# Create masks (must be tensors and on same device)\n",
    "src_mask = trainer.create_src_mask(src, pad_token_id=pad_token_id).to(device)\n",
    "tgt_mask = trainer.create_tgt_mask(tgt, pad_token_id=pad_token_id).to(device)\n",
    "\n",
    "# --- Tracing and Export ---\n",
    "# TorchScript trace\n",
    "traced_model = torch.jit.trace(model, (src, tgt, src_mask, tgt_mask))\n",
    "\n",
    "# Save TorchScript model (optional)\n",
    "traced_model.save(\"transformer_script.pt\")\n",
    "\n",
    "# Export to ONNX\n",
    "torch.onnx.export(\n",
    "    traced_model,\n",
    "    (src, tgt, src_mask, tgt_mask),\n",
    "    \"transformer.onnx\",\n",
    "    input_names=[\"src\", \"tgt\", \"src_mask\", \"tgt_mask\"],\n",
    "    output_names=[\"logits\"],\n",
    "    dynamic_axes={\n",
    "        \"src\": {1: \"src_len\"},\n",
    "        \"tgt\": {1: \"tgt_len\"},\n",
    "        \"logits\": {1: \"tgt_len\"}  # logits: (batch, tgt_len, vocab)\n",
    "    },\n",
    "    dynamo=True\n",
    ")\n",
    "print(\"✅ ONNX export completed: transformer.onnx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9711bd31",
   "metadata": {},
   "source": [
    "# Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc831255",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# take a batch from the validation loader\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#src_batch, tgt_batch = next(iter(valid_loader))\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# run inference\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#src_sentences = trainer.decode_ids(id_sequences=src_batch,)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m translate_sentences_non_batched\n\u001b[0;32m----> 9\u001b[0m translated_sentences_beam, in_tokens, out_tokens, attention \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate_sentences_non_batched\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mI like to eat pizza\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbeam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mreturn_attention\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(out_tokens[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(out_tokens)\n",
      "File \u001b[0;32m~/alpha_transformer/alpha_transformer/scripts/infer.py:52\u001b[0m, in \u001b[0;36mtranslate_sentences_non_batched\u001b[0;34m(trainer, sentences, decode_type, beam_size, return_attention)\u001b[0m\n\u001b[1;32m     50\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m input_tensor\u001b[38;5;241m.\u001b[39mto(trainer\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_attention:\n\u001b[0;32m---> 52\u001b[0m     decoded_sentence, output_ids, cross_attention \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecode_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mbeam_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeam_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_attention\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     attentions\u001b[38;5;241m.\u001b[39mappend(cross_attention)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/alpha_transformer/alpha_transformer/trainer.py:390\u001b[0m, in \u001b[0;36mTrainer.infer\u001b[0;34m(self, src, decode_type, beam_size, return_attention)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_attention:\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m beam_size:\n\u001b[0;32m--> 390\u001b[0m         generated_sequences, final_attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeam_search_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeam_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_attention\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         generated_sequences, final_attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeam_search_decode(src, return_attention\u001b[38;5;241m=\u001b[39mreturn_attention)\n",
      "File \u001b[0;32m~/miniconda3/envs/transformer/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/alpha_transformer/alpha_transformer/trainer.py:675\u001b[0m, in \u001b[0;36mTrainer.beam_search_decode\u001b[0;34m(self, src, beam_size, length_penalty_alpha, repetition_penalty, return_attention, debug_mode)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(generated_sequences[i]\u001b[38;5;241m.\u001b[39mtolist()):\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m next_token_log_probs[i, token] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 675\u001b[0m         next_token_log_probs[i, token] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m repetition_penalty\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    677\u001b[0m         next_token_log_probs[i, token] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m repetition_penalty\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# take a batch from the validation loader\n",
    "#src_batch, tgt_batch = next(iter(valid_loader))\n",
    "\n",
    "# send to device\n",
    "#src_batch = src_batch.to(device)\n",
    "# run inference\n",
    "#src_sentences = trainer.decode_ids(id_sequences=src_batch,)\n",
    "from scripts.infer import translate_sentences_non_batched\n",
    "translated_sentences_beam, in_tokens, out_tokens, attention = translate_sentences_non_batched(trainer, sentences=['I like to eat pizza'], decode_type='beam', beam_size=3,return_attention=True )\n",
    "\n",
    "print(len(out_tokens[0]))\n",
    "print(out_tokens)\n",
    "\n",
    "# Print some translations\n",
    "if False:\n",
    "    for idx in range(5):  # first 5 examples+\n",
    "        print(f'Source sentences: {src_sentences[idx]}')\n",
    "        print(f\"Predicted Translation Greedy: {translated_sentences[idx]}\")\n",
    "        print(f\"Predicted Translation Beam: {translated_sentences_beam[idx]}\")\n",
    "        print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "519d2732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"J'aime manger de la pizza que j'aime manger en mange à une pizza pizza.\"]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(translated_sentences_beam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb107095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
